{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Disease Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ISIC_2019_Training_Input',\n",
       " 'Skin Disease Dataset-20200416T224355Z-001.zip',\n",
       " 'SkinDiseaseDataset',\n",
       " 'test_df.csv',\n",
       " 'test_feat0.npy',\n",
       " 'test_feat1.npy',\n",
       " 'train_feat0.npy',\n",
       " 'train_feat1.npy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of occurences\n",
      "[ 4522 12875  3323   867  2624   239   253   628]\n",
      "Classes\n",
      "[0 1 2 3 4 5 6 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gnd_truth = pd.read_csv(\"data\\SkinDiseaseDataset\\ISIC_2019_Training_GroundTruth.csv\")\n",
    "#aug_df = pd.read_csv(\"data/augmentImageNameLabels.csv\")\n",
    "gnd_truth.head()\n",
    "\n",
    "IMG_NAMES = gnd_truth['image']\n",
    "TRAIN_IMG_RT_PATH = 'data/ISIC_2019_Training_Input/'\n",
    "TEST_IMG_RT_PATH = 'data/ISIC_2019_Test_Input'\n",
    "### No Examples of UNK so drop it\n",
    "labels = np.array(gnd_truth.drop(columns = [\"image\", \"UNK\"]))\n",
    "\n",
    "c, freq = np.unique(np.argmax(labels, axis= 1), return_counts = True)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"# of Occurences\")\n",
    "plt.bar(c,freq)\n",
    "print(\"# of occurences\")\n",
    "print(freq)\n",
    "print(\"Classes\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnClassIndex(trainY,class_index):\n",
    "    labels = np.argmax(trainY, axis = 1)\n",
    "    return [ i for i in range(len(labels)) if labels[i] == class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Randomly Balance Sample from classes  \n",
    "smpl_test_idxs = []\n",
    "smpl_train_idxs = []\n",
    "for i in range(len(labels[1])):\n",
    "    idxs = np.array(returnClassIndex(labels, i))\n",
    "    sel = np.random.RandomState(seed = 42).permutation(len(idxs))\n",
    "    #print(len(idxs))\n",
    "    ### Shuffle\n",
    "    train_sel = list(sel[:int(0.75*len(idxs))])\n",
    "    test_sel = list(sel[int(0.75*len(idxs)):])\n",
    "    smpl_train_idxs += list(idxs[train_sel])\n",
    "    smpl_test_idxs += list(idxs[test_sel])\n",
    "\n",
    "paths = np.array([TRAIN_IMG_RT_PATH + m +'.jpg' for m in IMG_NAMES ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size =200\n",
    "channels = 3\n",
    "num_classes = 8\n",
    "lr = 0.001 ### learning rate\n",
    "input_shape = ( im_size, im_size, channels)\n",
    "l1_lambda = 0 ### L1 regularization lambda parameter\n",
    "l2_lambda = 0\n",
    "keep_prob =  0\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpytr = labels[smpl_train_idxs]\n",
    "tmpytst = labels[smpl_test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_train_class = [0,1]\n",
    "true_train_class_idx = []\n",
    "for i in true_train_class:\n",
    "    if( i == 1):\n",
    "        true_train_class_idx = true_train_class_idx + returnClassIndex(tmpytr,i)[:3000]\n",
    "    else:\n",
    "        true_train_class_idx = true_train_class_idx + returnClassIndex(tmpytr,i)[:3000]\n",
    "false_train_class = [2,4]\n",
    "false_train_class_idx = []\n",
    "for i in false_train_class:\n",
    "    false_train_class_idx = false_train_class_idx + returnClassIndex(tmpytr,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10460"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_train_class_idx) + len(false_train_class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmpytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test_class1 = [0,1]\n",
    "true_test_class_idx1 = []\n",
    "for i in true_test_class1:\n",
    "    true_test_class_idx1 = true_test_class_idx1 + returnClassIndex(tmpytst,i)\n",
    "\n",
    "### Selecting the classes\n",
    "false_test_class = [2,3,4,5,6,7]\n",
    "false_test_class_idx = []\n",
    "for i in false_test_class:\n",
    "    false_test_class_idx = false_test_class_idx + returnClassIndex(tmpytst,i)\n",
    "trn_idx_shuffle = np.random.RandomState(seed= 42).permutation(\n",
    "    len(true_train_class_idx + false_train_class_idx)\n",
    ")\n",
    "tst_idx_shuffle = np.random.RandomState(\n",
    "    seed= 42).permutation(\n",
    "    len(true_test_class_idx1 +false_test_class_idx)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trueX = paths[smpl_train_idxs][true_train_class_idx]\n",
    "train_falseX = paths[smpl_train_idxs][false_train_class_idx]\n",
    "bin_trainX = np.vstack([train_trueX.reshape(-1,1),\n",
    "                        train_falseX.reshape(-1,1)])[trn_idx_shuffle]\n",
    "bin_trainY = np.array((len(train_trueX)*[1]) + (len(train_falseX)*[0]))[trn_idx_shuffle]\n",
    "\n",
    "test_trueX = paths[smpl_test_idxs][true_test_class_idx1]\n",
    "test_falseX = paths[smpl_test_idxs][false_test_class_idx]\n",
    "bin_testX = np.vstack([test_trueX.reshape(-1,1),\n",
    "                       train_falseX.reshape(-1,1)])[tst_idx_shuffle]\n",
    "bin_testY = np.array((len(test_trueX)*[1]) + (len(test_falseX)*[0]))[tst_idx_shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10460 validated image filenames belonging to 2 classes.\n",
      "Found 6335 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "### Dataframes for Generator\n",
    "train_df = pd.DataFrame({\"filename\":bin_trainX.ravel(),\n",
    "                        \"class\": bin_trainY.astype(str)})\n",
    "test_df = pd.DataFrame({\"filename\":bin_testX.ravel(),\n",
    "                        \"class\": bin_testY.astype(str)})\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1.0/255,\n",
    "        samplewise_center = True,\n",
    "        samplewise_std_normalization = True, \n",
    "        horizontal_flip=True,\n",
    "        vertical_flip = True,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=0.5,\n",
    "        rotation_range = 30\n",
    ")\n",
    "batch_size = 25\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    class_mode = 'binary',\n",
    "    y_col=\"class\",\n",
    "    batch_size = batch_size, \n",
    "    target_size = (im_size, im_size),\n",
    "    shuffle = False\n",
    ")\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    class_mode = 'binary',\n",
    "    y_col=\"class\",\n",
    "    batch_size = batch_size,\n",
    "    target_size = (im_size, im_size),\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 206, 206, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 100, 100, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 100, 100, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 100, 100, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 102, 102, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 50, 50, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 50, 50, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 50, 50, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 50, 50, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 50, 50, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 50, 50, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 50, 50, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 50, 50, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 50, 50, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 50, 50, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 50, 50, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 50, 50, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 50, 50, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 50, 50, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 50, 50, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 50, 50, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 50, 50, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 50, 50, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 50, 50, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 50, 50, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 25, 25, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 25, 25, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 25, 25, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 25, 25, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 25, 25, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 25, 25, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 25, 25, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 25, 25, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 25, 25, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 25, 25, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 25, 25, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 25, 25, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 25, 25, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 25, 25, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 25, 25, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 25, 25, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 25, 25, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 25, 25, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 25, 25, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 25, 25, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 25, 25, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 13, 13, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 13, 13, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 13, 13, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 13, 13, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 13, 13, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 13, 13, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 13, 13, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 13, 13, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 13, 13, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 13, 13, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 13, 13, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 13, 13, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 13, 13, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 13, 13, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 13, 13, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 13, 13, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 13, 13, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 13, 13, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 13, 13, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 13, 13, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 13, 13, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 13, 13, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 13, 13, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 13, 13, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 13, 13, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 13, 13, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "#model.add(layers.UpSampling2D((2,2)))\n",
    "#model.add(layers.UpSampling2D((2,2)))\n",
    "#model.add(layers.UpSampling2D((2,2)))\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(128, activation='elu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(128, activation='elu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='elu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 419 steps, validate for 254 steps\n",
      "Epoch 1/20\n",
      "419/419 [==============================] - 367s 876ms/step - loss: 0.4708 - acc: 0.7836 - val_loss: 0.7668 - val_acc: 0.7056\n",
      "Epoch 2/20\n",
      "419/419 [==============================] - 356s 849ms/step - loss: 0.4318 - acc: 0.8037 - val_loss: 0.5600 - val_acc: 0.7356\n",
      "Epoch 3/20\n",
      "419/419 [==============================] - 369s 881ms/step - loss: 0.4115 - acc: 0.8149 - val_loss: 0.5973 - val_acc: 0.7206\n",
      "Epoch 4/20\n",
      "419/419 [==============================] - 369s 880ms/step - loss: 0.3970 - acc: 0.8214 - val_loss: 0.7691 - val_acc: 0.7140\n",
      "Epoch 5/20\n",
      "419/419 [==============================] - 363s 867ms/step - loss: 0.3793 - acc: 0.8356 - val_loss: 0.8485 - val_acc: 0.7157\n",
      "Epoch 6/20\n",
      "419/419 [==============================] - 391s 934ms/step - loss: 0.3650 - acc: 0.8401 - val_loss: 0.7795 - val_acc: 0.7257\n",
      "Epoch 7/20\n",
      "419/419 [==============================] - 400s 954ms/step - loss: 0.3523 - acc: 0.8532 - val_loss: 0.5922 - val_acc: 0.7504\n",
      "Epoch 8/20\n",
      "419/419 [==============================] - 365s 871ms/step - loss: 0.3389 - acc: 0.8572 - val_loss: 0.6893 - val_acc: 0.7667\n",
      "Epoch 9/20\n",
      "419/419 [==============================] - 348s 831ms/step - loss: 0.3277 - acc: 0.8604 - val_loss: 0.6573 - val_acc: 0.7743\n",
      "Epoch 10/20\n",
      "419/419 [==============================] - 342s 817ms/step - loss: 0.3186 - acc: 0.8662 - val_loss: 0.6265 - val_acc: 0.7446\n",
      "Epoch 11/20\n",
      "419/419 [==============================] - 352s 839ms/step - loss: 0.3038 - acc: 0.8717 - val_loss: 0.7313 - val_acc: 0.7348\n",
      "Epoch 12/20\n",
      "404/419 [===========================>..] - ETA: 10s - loss: 0.2968 - acc: 0.8755"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d544539dade8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m history = model.fit(train_generator, epochs=20,\n\u001b[1;32m----> 5\u001b[1;33m                                        \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                    )\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), \n",
    "              loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_generator, epochs=20,\n",
    "                    validation_data=test_generator\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "317/317 [==============================] - 117s 368ms/step - loss: 0.6541 - acc: 0.7274\n",
      "acc: 72.74%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='binary_skin_disease_resnet_No_AUG_88acc.png')\n",
    "\n",
    "\n",
    "scores = model.evaluate(test_generator, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "# Serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"Models/binary_skin_disease_resnet_No_AUG_88acc.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# Serialize weights to HDF5\n",
    "model.save_weights(\"Models/binary_skin_disease_resnet_No_AUG_88acc.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Models/skin_disease_resnet_No_AUG_88acc.json\", 'r') as j_file:\n",
    "    loaded_model_json = j_file.read()\n",
    "model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "model.load_weights(\"Models/skin_disease_resnet_No_AUG_88acc.h5\")\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy',\n",
    "              metrics=['acc']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "396/396 [==============================] - 128s 323ms/step - loss: 0.3081 - acc: 0.8896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3080926376084487, 0.8895817]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 396/396 [03:01<00:00,  2.18it/s]\n"
     ]
    }
   ],
   "source": [
    "testY1 = []\n",
    "preds1 = []\n",
    "\n",
    "for i in tqdm(range(len(test_generator))):\n",
    "    tmp = next(test_generator)\n",
    "    preds1.append(model.predict_on_batch(tmp[0].astype(np.float32)))\n",
    "    testY1.append(tmp[1].astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testY = []\n",
    "preds = []\n",
    "for i in tqdm(range(len(paths[smpl_test_idxs]))):\n",
    "    img = plt.imread(paths[smpl_test_idxs][i])\n",
    "    preds.append(model.predict(np.expand_dims(cv2.resize(img/255, (200,200)), axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.vstack(testY1)\n",
    "p = np.vstack(preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.argmax(t, axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.argmax(p,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(t1, p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6000934118313836\n",
      "Accuracy: 0.5390686661404893\n",
      "F1 Score: 0.13297292481672698\n",
      "recall Score: 0.1515031825820848\n",
      "Precision Score: 0.25332833124586684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import log_loss, roc_curve\n",
    "\n",
    "f1 = f1_score(groundTruth, pred, average = \"macro\")\n",
    "acc = accuracy_score(groundTruth, p_)\n",
    "recall = recall_score(groundTruth, pred,average = \"macro\")\n",
    "precision =precision_score(groundTruth, pred, average = \"macro\")\n",
    "loss = log_loss(testY_,preds)\n",
    "\n",
    "print(\"Loss: {}\".format(loss))\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "print(\"F1 Score: {}\".format(f1))\n",
    "print(\"recall Score: {}\".format(recall))\n",
    "print(\"Precision Score: {}\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdive",
   "language": "python",
   "name": "deepdive"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
